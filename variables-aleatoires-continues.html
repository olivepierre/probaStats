<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 4 Variables aléatoires continues | Probabilités et statistiques</title>
  <meta name="description" content="Ce document fournit des éléments en probabilités et statistiques, illustrés en R." />
  <meta name="generator" content="bookdown 0.11.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 4 Variables aléatoires continues | Probabilités et statistiques" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce document fournit des éléments en probabilités et statistiques, illustrés en R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 4 Variables aléatoires continues | Probabilités et statistiques" />
  
  <meta name="twitter:description" content="Ce document fournit des éléments en probabilités et statistiques, illustrés en R." />
  

<meta name="author" content="Pierre-Damien Olive" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variables-aleatoires-discretes.html">
<link rel="next" href="statistique-descriptive.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Probabilités</b></span></li>
<li class="chapter" data-level="1" data-path="evenements-et-probabilites.html"><a href="evenements-et-probabilites.html"><i class="fa fa-check"></i><b>1</b> Évènements et probabilités</a><ul>
<li class="chapter" data-level="1.1" data-path="evenements-et-probabilites.html"><a href="evenements-et-probabilites.html#evenements"><i class="fa fa-check"></i><b>1.1</b> Évènements</a></li>
<li class="chapter" data-level="1.2" data-path="evenements-et-probabilites.html"><a href="evenements-et-probabilites.html#probabilites"><i class="fa fa-check"></i><b>1.2</b> Probabilités</a></li>
<li class="chapter" data-level="1.3" data-path="evenements-et-probabilites.html"><a href="evenements-et-probabilites.html#probabilites-conditionnelles"><i class="fa fa-check"></i><b>1.3</b> Probabilités conditionnelles</a></li>
<li class="chapter" data-level="1.4" data-path="evenements-et-probabilites.html"><a href="evenements-et-probabilites.html#independance"><i class="fa fa-check"></i><b>1.4</b> Indépendance</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatoires.html"><a href="variables-aleatoires.html"><i class="fa fa-check"></i><b>2</b> Variables aléatoires</a><ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatoires.html"><a href="variables-aleatoires.html#variables-aleatoires-1"><i class="fa fa-check"></i><b>2.1</b> Variables aléatoires</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatoires.html"><a href="variables-aleatoires.html#variables-discretes-et-continues"><i class="fa fa-check"></i><b>2.2</b> Variables discrètes et continues</a></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatoires.html"><a href="variables-aleatoires.html#vecteurs-aleatoires"><i class="fa fa-check"></i><b>2.3</b> Vecteurs aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html"><i class="fa fa-check"></i><b>3</b> Variables aléatoires discrètes</a><ul>
<li class="chapter" data-level="3.1" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#fonctions-de-masse"><i class="fa fa-check"></i><b>3.1</b> Fonctions de masse</a></li>
<li class="chapter" data-level="3.2" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#independance-1"><i class="fa fa-check"></i><b>3.2</b> Indépendance</a></li>
<li class="chapter" data-level="3.3" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#esperance"><i class="fa fa-check"></i><b>3.3</b> Espérance</a></li>
<li class="chapter" data-level="3.4" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#cas-particuliers-de-variables-discretes-aleatoires"><i class="fa fa-check"></i><b>3.4</b> Cas particuliers de variables discrètes aléatoires</a></li>
<li class="chapter" data-level="3.5" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#dependance"><i class="fa fa-check"></i><b>3.5</b> Dépendance</a></li>
<li class="chapter" data-level="3.6" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#loi-conditionnelle-et-esperance-conditionnelle"><i class="fa fa-check"></i><b>3.6</b> Loi conditionnelle et espérance conditionnelle</a></li>
<li class="chapter" data-level="3.7" data-path="variables-aleatoires-discretes.html"><a href="variables-aleatoires-discretes.html#somme-de-variables-aleatoires-discretes"><i class="fa fa-check"></i><b>3.7</b> Somme de variables aléatoires discrètes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html"><i class="fa fa-check"></i><b>4</b> Variables aléatoires continues</a><ul>
<li class="chapter" data-level="4.1" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#densites-de-probabilites"><i class="fa fa-check"></i><b>4.1</b> densités de probabilités</a></li>
<li class="chapter" data-level="4.2" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#independance-2"><i class="fa fa-check"></i><b>4.2</b> Indépendance</a></li>
<li class="chapter" data-level="4.3" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#exemples-de-variables-aleatoires-continues"><i class="fa fa-check"></i><b>4.3</b> Exemples de variables aléatoires continues</a></li>
<li class="chapter" data-level="4.4" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#dependance-1"><i class="fa fa-check"></i><b>4.4</b> Dépendance</a></li>
<li class="chapter" data-level="4.5" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#somme-de-variables-aleatoires"><i class="fa fa-check"></i><b>4.5</b> Somme de variables aléatoires</a></li>
<li class="chapter" data-level="4.6" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#la-loi-normale-multivariee"><i class="fa fa-check"></i><b>4.6</b> La loi normale multivariée</a></li>
<li class="chapter" data-level="4.7" data-path="variables-aleatoires-continues.html"><a href="variables-aleatoires-continues.html#lois-issues-de-la-loi-normale"><i class="fa fa-check"></i><b>4.7</b> Lois issues de la loi normale</a></li>
</ul></li>
<li class="part"><span><b>II Statistiques</b></span></li>
<li class="appendix"><span><b>Annexes</b></span></li>
<li class="chapter" data-level="A" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html"><i class="fa fa-check"></i><b>A</b> Statistique descriptive</a><ul>
<li class="chapter" data-level="A.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#distribution-univariee"><i class="fa fa-check"></i><b>A.1</b> Distribution univariée</a></li>
<li class="chapter" data-level="A.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#distribution-bivariee"><i class="fa fa-check"></i><b>A.2</b> Distribution bivariée</a></li>
<li class="chapter" data-level="A.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#series-temporelles"><i class="fa fa-check"></i><b>A.3</b> Séries temporelles</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="techniques-de-denombrement-en-probabilite.html"><a href="techniques-de-denombrement-en-probabilite.html"><i class="fa fa-check"></i><b>B</b> Techniques de dénombrement en probabilité</a></li>
<li class="chapter" data-level="C" data-path="fonctions-indicatrices.html"><a href="fonctions-indicatrices.html"><i class="fa fa-check"></i><b>C</b> Fonctions indicatrices</a></li>
<li class="chapter" data-level="D" data-path="espaces-lp.html"><a href="espaces-lp.html"><i class="fa fa-check"></i><b>D</b> Espaces <span class="math inline">\(L^p\)</span></a></li>
<li class="chapter" data-level="E" data-path="echantillonage.html"><a href="echantillonage.html"><i class="fa fa-check"></i><b>E</b> Échantillonage</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probabilités et statistiques</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variables-aleatoires-continues" class="section level1">
<h1><span class="header-section-number">Chapitre 4</span> Variables aléatoires continues</h1>
<div id="densites-de-probabilites" class="section level2">
<h2><span class="header-section-number">4.1</span> densités de probabilités</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-37" class="definition"><strong>Définition 4.1  </strong></span>Une variable aléatoire réelle <span class="math inline">\(X\)</span> est dite <strong>continue</strong> s’il existe une fonction f positive telle que <span class="math display">\[F_X(x) = \int_{-\infty}^x f(t) \mbox{d}t\]</span> Une telle fonction est une <strong>densité</strong> de <span class="math inline">\(X\)</span>. Cette densité n’est pas unique. Une telle densité est généralement notée <span class="math inline">\(f_X\)</span>.</p>
Lorsque <span class="math inline">\(F_X\)</span> est dérivable, <span class="math inline">\(F_X&#39;\)</span> est une densité de <span class="math inline">\(X\)</span>.
</div>


<div class="lemma">
<p><span id="lem:unnamed-chunk-38" class="lemma"><strong>Lemme 4.1  </strong></span>Si <span class="math inline">\(X\)</span> admet <span class="math inline">\(f\)</span> comme densité, alors:</p>
<ul>
<li><p><span class="math inline">\(\int_{-\infty}^{+\infty} f(x) \mbox{d}x = 1\)</span>;</p></li>
<li><p><span class="math inline">\(\mathbb{P}(X=x)=0, \forall x \in \mathbb{R}\)</span>;</p></li>
<li><p><span class="math inline">\(\mathbb{P}(X \in \mathcal{E}) = \int_{\mathcal{E}} f(x) \mbox{d}x\)</span> pour tout évènement <span class="math inline">\(\mathcal{E}\)</span>;</p></li>
<li><p><span class="math inline">\(X\)</span> et <span class="math inline">\(-X\)</span> ont les mêmes distributions si et seulement si <span class="math inline">\(f_X\)</span> est paire;</p></li>
<li>Si <span class="math inline">\(f\)</span> et <span class="math inline">\(g\)</span> sont des densités, il en est de même pour <span class="math inline">\(\lambda f + (1-\lambda)g\)</span> pour <span class="math inline">\(0 \leq \lambda \leq 1\)</span>.
</div>
</li>
</ul>

<div class="example">
<span id="exm:unnamed-chunk-39" class="example"><strong>Exemple 4.1  </strong></span>Soient <span class="math inline">\(a,b\)</span> deux réels avec <span class="math inline">\(a&lt;b\)</span>. La <strong>loi uniforme</strong> sur l’intervalle <span class="math inline">\([a,b]\)</span> est définie par sa densité de probabilité <span class="math display">\[
f(x) = \left\lbrace
\begin{array}{ccc}
\frac{1}{b-a}  &amp; \mbox{si} &amp; a \leq x \leq b\\
0 &amp; \mbox{sinon} &amp;\\
\end{array}\right.
\]</span> On note cette loi <span class="math inline">\(\mathcal{U}(a,b)\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-40" class="example"><strong>Exemple 4.2  </strong></span>La <strong>loi exponentielle</strong> modélise la durée de vie d’un phénomène sans mémoire : la probabilité que le phénomène dure au moins <span class="math inline">\(s+t\)</span> sachant qu’il a déjà duré <span class="math inline">\(t\)</span> est la même que la probabilié de durer <span class="math inline">\(s\)</span> à partir de la mise en fonction initiale.</p>
Soit <span class="math inline">\(\lambda &gt; 0\)</span>. La densité associée à cette loi est : <span class="math display">\[
f(t) = \left\lbrace
\begin{array}{ccc}
\lambda e^{-\lambda t}  &amp; \mbox{si} &amp; t&gt;0\\
0 &amp; \mbox{sinon} &amp;\\
\end{array}\right.
\]</span> On note la loi exponentielle de paramètre <span class="math inline">\(\lambda\)</span> : <span class="math inline">\(\mathcal{E}(\lambda)\)</span>.
</div>
 
<div class="lemma">
<p><span id="lem:unnamed-chunk-41" class="lemma"><strong>Lemme 4.2  </strong></span>Soient <span class="math inline">\(X,Y\)</span> deux variables aléatoires qui suivent deux lois exponentielles, de paramètres <span class="math inline">\(\lambda, \mu\)</span>, alors <span class="math inline">\(\min (X,Y)\)</span> suit encore une loi exponentielle, de paramètre <span class="math inline">\(\lambda + \mu\)</span>.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-42" class="example"><strong>Exemple 4.3  </strong></span>La loi <strong>Gamma</strong> (qui généralise la loi exponentielle) modélise également des durées; elle est caractérisée par deux paramètres <span class="math inline">\(k,\theta\)</span> positifs.</p>
<p>Sa densité est <span class="math display">\[ f(t) = \left\lbrace
\begin{array}{ccc}
\frac{t^{k-1} \exp \left(-\frac{t}{\theta} \right)}{\theta^k \Gamma (k)}   &amp; \mbox{si} &amp; x&gt;0\\
0 &amp; \mbox{sinon} &amp; \\
\end{array}\right.
\]</span> où <span class="math inline">\(\Gamma\)</span> désigne la fonction Gamma d’Euler (<span class="math inline">\(\Gamma : z \mapsto \int_0^{+\infty} t^{z-1} e^{-t} \mbox{d}t\)</span>).</p>
On note cette loi <span class="math inline">\(\Gamma(k,\theta)\)</span>.
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-43" class="lemma"><strong>Lemme 4.3  </strong></span>Soient <span class="math inline">\(X_1, \ldots, X_n\)</span> des variables aléatoires indépendantes, de loi <span class="math inline">\(\Gamma(k_1,\theta),\ldots,\Gamma(k_n,\theta)\)</span>. Alors <span class="math inline">\(X_1+\ldots+X_n\)</span> suit une loi <span class="math inline">\(\Gamma(\sum_{i=1}^n k_i,\theta)\)</span>.
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-44" class="lemma"><strong>Lemme 4.4  </strong></span>Soit <span class="math inline">\(X \sim \Gamma(k,\theta)\)</span> et <span class="math inline">\(t&gt;0\)</span>. Alors <span class="math inline">\(tX \sim \Gamma(k,t \theta)\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-45" class="example"><strong>Exemple 4.4  </strong></span>La <strong>loi normale</strong> est définie suivant deux paramètres (<span class="math inline">\(\mu \in \mathbb{R}, \sigma &gt;0\)</span>) par sa densité:</p>
<span class="math display">\[
  f(x) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^2}{2 \sigma^2}\right)
  \]</span> On note la loi <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span>.
</div>


<div class="example">
<span id="exm:unnamed-chunk-46" class="example"><strong>Exemple 4.5  </strong></span>Soit <span class="math inline">\(X\)</span> une variable aléatoire qui suit une loi normale <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span>. Alors <span class="math inline">\(\exp(X)\)</span> suit une loi <strong>log-normale</strong>.
</div>

</div>
<div id="independance-2" class="section level2">
<h2><span class="header-section-number">4.2</span> Indépendance</h2>

<div class="definition">
<span id="def:unnamed-chunk-47" class="definition"><strong>Définition 4.2  </strong></span>Soient <span class="math inline">\(X,Y\)</span> deux variables aléatoires réelles. On dit que les variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont <strong>indépendantes</strong> si les évènements <span class="math inline">\(\lbrace X \leq x \rbrace\)</span> et <span class="math inline">\(\lbrace Y \leq y \rbrace\)</span> sont indépendants pour tous <span class="math inline">\(x,y\)</span> réels.
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-48" class="theorem"><strong>Théorème 4.1  </strong></span>Soient <span class="math inline">\(X,Y\)</span> deux variables aléatoires, <span class="math inline">\(f,g\)</span> deux fonctions telles que <span class="math inline">\(f(X), g(Y)\)</span> soient des variables aléatoires.</p>
<p>Si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, il en est de même pour <span class="math inline">\(f(X)\)</span> et <span class="math inline">\(g(Y)\)</span>.```</p>
<h2 id="esperance-1"><span class="header-section-number">4.2</span> Espérance</h2>
</div>
 
<div class="definition">
<span id="def:unnamed-chunk-49" class="definition"><strong>Définition 4.3  </strong></span><strong>L’espérance</strong> d’une variable aléatoire <span class="math inline">\(X\)</span> de densité <span class="math inline">\(f\)</span> est définie par <span class="math display">\[\mathbb{E}X = \int_{-\infty}^{+\infty} x f(x) \mbox{d}x\]</span> lorsque cette intégrale existe.
</div>
 
<div class="theorem">
<span id="thm:unnamed-chunk-50" class="theorem"><strong>Théorème 4.2  </strong></span>Si <span class="math inline">\(X\)</span> et <span class="math inline">\(g(X)\)</span> sont des variables aléatoires, alors <span class="math display">\[\mathbb{E}g(X) = \int_{-\infty}^{+\infty} g(x) f(x) \mbox{d}x\]</span>
</div>
 
<div class="lemma">
<span id="lem:unnamed-chunk-51" class="lemma"><strong>Lemme 4.5  </strong></span>Si <span class="math inline">\(X\)</span> admet une densité nulle sur <span class="math inline">\(\mathbb{R}^-\)</span> et une fonction de répartition <span class="math inline">\(F\)</span>, alors <span class="math display">\[\mathbb{E}X = \int_0^{+\infty} (1-F(x)) \mbox{d}x = \int_0^{+\infty} \mathbb{P}(X&gt;x) \mbox{d}x\]</span>
</div>
<p> Les autres propriétés de l’espérance, vues dans le chapitre sur les variables aléatoires discrètes, s’étendent sans difficultés aux variables continues (moments, moments centrés, variance, covariance, corrélation).</p>
</div>
<div id="exemples-de-variables-aleatoires-continues" class="section level2">
<h2><span class="header-section-number">4.3</span> Exemples de variables aléatoires continues</h2>

<div class="theorem">
<p><span id="thm:unnamed-chunk-52" class="theorem"><strong>Théorème 4.3  </strong></span>L’espérance et la variance des lois continues de référence sont recensés dans le tableau ci-après :</p>
<table>
<thead>
<tr class="header">
<th align="center">Loi</th>
<th align="center">Espérance</th>
<th align="center">Variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{U}(a,b)\)</span></td>
<td align="center"><span class="math inline">\(\frac{a+b}{2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{(b-a)^2}{12}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{E}(\lambda)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\lambda}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{\lambda^2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\Gamma(k,\theta)\)</span></td>
<td align="center"><span class="math inline">\(k \theta\)</span></td>
<td align="center"><span class="math inline">\(k \theta^2\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\mu\)</span></td>
<td align="center"><span class="math inline">\(\sigma^2\)</span></td>
</tr>
</tbody>
</table>
</div>

</div>
<div id="dependance-1" class="section level2">
<h2><span class="header-section-number">4.4</span> Dépendance</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-53" class="definition"><strong>Définition 4.4  </strong></span>Soient <span class="math inline">\(X,Y\)</span> deux variables aléatoires réelles. Ces variables sont <strong>conjointement continues</strong> s’il existe une fonction positive <span class="math inline">\(f\)</span> telle que:</p>
<span class="math display">\[F(x,y) = \mathbb{P}(X \leq x , Y \leq y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) \mbox{d}u \mbox{d}v\]</span> f est une densité du couple <span class="math inline">\((X,Y)\)</span>. Si <span class="math inline">\(F\)</span> est dérivable, on peut prendre <span class="math display">\[f = \frac{\partial^2 F}{\partial x \partial y}\]</span>
</div>


<div class="lemma">
<p><span id="lem:unnamed-chunk-54" class="lemma"><strong>Lemme 4.6  </strong></span>On a <span class="math display">\[
  \mathbb{P}(a \leq X \leq b ; c \leq Y \leq d) = F(b,d) - F(a,d) - F(b,c)+F(a,c)
  = \int_{a}^b \int_{c}^d f(u,v) \mbox{d}u \mbox{d}v
\]</span> Plus généralement, si <span class="math inline">\(\mathcal{E}\)</span> est un évènement, on a:</p>
<span class="math display">\[
  \mathbb{P}\left( (X,Y) \in \mathcal{E} \right) = \iint_{\mathcal{E}} f(u,v) \mbox{d}u \mbox{d}v
  \]</span>
</div>


<div class="definition">
<span id="def:unnamed-chunk-55" class="definition"><strong>Définition 4.5  </strong></span>Les <strong>fonctions de répartition marginales</strong> de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont définies par <span class="math display">\[
  F_X(x) = \mathbb{P}(X  \leq x) = \int_{-\infty}^x \int_{-\infty}^{+\infty} f(u,v) \mbox{d}u \mbox{d}v ; F_Y(y) = \mathbb{P}(Y  \leq y) = \int_{-\infty}^{+\infty} \int_{-\infty}^y  f(u,v) \mbox{d}u \mbox{d}v 
  \]</span> On en déduit les <strong>densités marginales</strong> selon <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> : <span class="math display">\[
  f_X(x) = \int_{-\infty}^{+\infty} f(x,y) \mbox{d}y ; f_Y(y) = \int_{-\infty}^{+\infty} f(x,y) \mbox{d}x
  \]</span>
</div>


<div class="theorem">
<span id="thm:unnamed-chunk-56" class="theorem"><strong>Théorème 4.4  </strong></span>Soit <span class="math inline">\(g : \mathbb{R}^2 \to \mathbb{R}\)</span> telle que <span class="math inline">\(g(X,Y)\)</span> soit une variable aléatoire. Alors, <span class="math display">\[
  \mathbb{E} g(X,Y) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(u,v) f(u,v) \mbox{d}u \mbox{d}v
  \]</span> dès que cette intégrale est définie.
</div>


<div class="theorem">
<span id="thm:unnamed-chunk-57" class="theorem"><strong>Théorème 4.5  </strong></span>Les variables <span class="math inline">\(X,Y\)</span> sont indépendantes si et seulement si <span class="math display">\[F_{X,Y} = F_X F_Y \iff f_{X,Y} = f_x f_y.\]</span>
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-58" class="theorem"><strong>Théorème 4.6  </strong></span>Soit <span class="math inline">\(X,Y\)</span> deux variables aléatoires continues. Alors <span class="math display">\[\left( \mathbb{E}XY \right)^2 \leq \left( \mathbb{E} X^2\right) \left( \mathbb{E} Y^2\right)\]</span> avec égalité si et seulement si il existe des réels <span class="math inline">\(\lambda,\mu\)</span> non tous nuls tels que <span class="math display">\[\mathbb{P}(\lambda X + \mu Y = 0) = 1.\]</span></p>
</div>
<p> ## Loi conditionnelle et espérance conditionnelle</p>
Soient <span class="math inline">\(X,Y\)</span> deux variables aléatoires continues, de densité jointe <span class="math inline">\(f\)</span>. 
<div class="definition">
<p><span id="def:unnamed-chunk-59" class="definition"><strong>Définition 4.6  </strong></span>La <strong>fonction de répartition conditionnelle</strong> de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=x\)</span> est définie par</p>
<span class="math display">\[
F_{Y|X}(y|x) = \int_{-\infty}^y \frac{f(x,v)}{f_X(x)} \mbox{d}v  
\]</span> pour tout <span class="math inline">\(x\)</span> tel que <span class="math inline">\(f_X(x)&gt;0\)</span>. Elle est également notée <span class="math display">\[\mathbb{P}(Y \leq y | X = x)\]</span>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-60" class="definition"><strong>Définition 4.7  </strong></span>La <strong>densité conditionnelle</strong> de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=x\)</span> est définie par</p>
<span class="math display">\[
f_{Y|X}(y|x) = \frac{f(x,y)}{f_X(x)} 
\]</span> pour tout <span class="math inline">\(x\)</span> tel que <span class="math inline">\(f_X(x)&gt;0\)</span>. Encore, <span class="math display">\[
  f_{Y|X} = \frac{f_{X,Y}}{f_X} 
\]</span>
</div>


<div class="theorem">
<span id="thm:unnamed-chunk-61" class="theorem"><strong>Théorème 4.7  </strong></span><strong>L’espérance conditionnelle</strong> de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X\)</span> est définie comme <span class="math display">\[\mathbb{E}(Y|X=x) = \int_{-\infty}^{+\infty} y f_{Y|X}(y|x) \mbox{d}y ;\]</span> Elle vérifie la relation <span class="math display">\[
\mathbb{E} \left(\mathbb{E}(Y|X) \right) = \mathbb{E} Y .
\]</span> Plus généralement, pour toute fonction <span class="math inline">\(g\)</span> pour laquelle l’expression a un sens, on a : <span class="math display">\[
\mathbb{E}  \left(g(X) \mathbb{E}(Y|X) \right) = \mathbb{E} Y g(X) .
\]</span>
</div>
<p> ## Fonctions de variables aléatoires</p>

<div class="theorem">
<span id="thm:unnamed-chunk-62" class="theorem"><strong>Théorème 4.8  </strong></span>Soit <span class="math inline">\(X\)</span> une variable aléatoire avec une densité <span class="math inline">\(f\)</span>, et soit <span class="math inline">\(g\)</span> une fonction réelle telle que <span class="math inline">\(Y = g(X)\)</span> soit encore une variable aléatoire. La fonction de répartition de <span class="math inline">\(Y\)</span> est définie par : <span class="math display">\[
  \mathbb{P}(Y \leq y) = \mathbb{P} \left(X \in g^{-1}(]-\infty , y]) \right) .
  \]</span>
</div>
 Plus généralement, on a le théorème suivant: 
<div class="theorem">
<p><span id="thm:unnamed-chunk-63" class="theorem"><strong>Théorème 4.9  </strong></span>Soient <span class="math inline">\(\mathcal{U}, \mathcal{V}\)</span> deux ouverts de <span class="math inline">\(\mathbb{R}^d\)</span>, Soit <span class="math inline">\(X\)</span> une variable aléatoire à valeurs dans <span class="math inline">\(\mathcal{U}\)</span> de densité <span class="math inline">\(f\)</span> et soit <span class="math inline">\(T\)</span> un difféomorphisme de classe <span class="math inline">\(\mathcal{C}^1 : \mathcal {U} \to \mathcal{V}\)</span>. La densité de la variable aléatoire <span class="math inline">\(Y = \varphi(X)\)</span> est définie par :</p>
<span class="math display">\[
f_Y(y) = \left\lbrace
\begin{array}{ccc}
f_X(\varphi^{-1}(y)) |J_{\varphi^{-1}}(y)|  &amp; \mbox{si} &amp; y \in \mathcal{V}\\
0 &amp; \mbox{sinon} &amp;\\
\end{array}\right.
\]</span> en notant <span class="math inline">\(|J_{\varphi^{-1}}(y)|\)</span> le déterminant du jacobien de <span class="math inline">\(\varphi^{-1}\)</span>, c’est-à-dire de la matrice de terme général <span class="math inline">\(\left(\frac{\partial \varphi^{-1}_j}{ \partial y_i} \right)_{i,j}\)</span>.
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-64" class="lemma"><strong>Lemme 4.7  </strong></span>Pour <span class="math inline">\(d=2\)</span>, le changement de variables “passage en coordonnées polaires” transforme une densité <span class="math inline">\(f(x,y)\)</span> en <span class="math inline">\(f(r \cos \theta, r \sin \theta) r\)</span>.
</div>

</div>
<div id="somme-de-variables-aleatoires" class="section level2">
<h2><span class="header-section-number">4.5</span> Somme de variables aléatoires</h2>

<div class="theorem">
<p><span id="thm:unnamed-chunk-65" class="theorem"><strong>Théorème 4.10  </strong></span>Si <span class="math inline">\(X,Y\)</span> ont pour densité jointe <span class="math inline">\(f\)</span>, alors la densité de <span class="math inline">\(Z = X+Y\)</span> est définie par:</p>
<span class="math display">\[
  f_Z(z) = \int_{-\infty}^{+\infty} f(x,z-x) \mbox{d}x
  \]</span> Si, <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, le résultat devient : <span class="math display">\[
  f_Z(z) = \int_{-\infty}^{+\infty} f_X(z-y) f_Y(y) \mbox{d}y = \int_{-\infty}^{+\infty} f_X(x) f_Y(z-x) \mbox{d}x
  \]</span> On dit que <span class="math inline">\(f_Z\)</span> est le <strong>produit de convolution</strong> de <span class="math inline">\(f_X\)</span> et <span class="math inline">\(f_Y\)</span>, noté <span class="math inline">\(f_X \star f_Y\)</span>.
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-66" class="lemma"><strong>Lemme 4.8  </strong></span>Soit <span class="math inline">\(X \sim \mathcal{N}(\mu_1,\sigma_1^2)\)</span> et <span class="math inline">\(Y \sim \mathcal{N}(\mu_2,\sigma_2^2)\)</span>. Supposons que <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes. Alors <span class="math inline">\(X+Y \sim \mathcal{N}(\mu_1 + \mu_2,\sigma_1^2 + \sigma_2^2)\)</span>.
</div>

</div>
<div id="la-loi-normale-multivariee" class="section level2">
<h2><span class="header-section-number">4.6</span> La loi normale multivariée</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-67" class="definition"><strong>Définition 4.8  </strong></span>Le vecteur <span class="math inline">\(X = (X_1, \ldots, X_n)\)</span> suit une <strong>loi normale multivariée</strong> (notée <span class="math inline">\(\mathcal{N}(\mu,\Sigma)\)</span>) s’il existe un vecteur <span class="math inline">\(\mu = (\mu_1,\ldots,\mu_n)\)</span> de réels et une matrice symétrique définie positive <span class="math inline">\(\Sigma\)</span> telle que la densité jointe de <span class="math inline">\(X\)</span> soit:</p>
<p><span class="math display">\[f_X(x) = \frac{1}{\sqrt{(2\pi)^n |\Sigma|}} \exp \left( 
-\frac12 (x-\mu)\Sigma^{-1}(x-\mu)&#39;
\right)\]</span></p>
De façon équivalente, on dit que le vecteur <span class="math inline">\(X\)</span> suit une loi normale multivariée si et seulement si pour tout vecteur <span class="math inline">\(a \in \mathbb{R}^n\)</span>, <span class="math inline">\(Xa&#39;\)</span> suit une loi normale.
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-68" class="theorem"><strong>Théorème 4.11  </strong></span>Si <span class="math inline">\(X\)</span> suit une loi <span class="math inline">\(\mathcal{N}(\mu,\Sigma)\)</span>, alors</p>
<ul>
<li><p><span class="math inline">\(\mathbb{E}X = \mu\)</span></p></li>
<li><p>la matrice <span class="math inline">\(\Sigma\)</span> est la matrice de covariance de <span class="math inline">\(X\)</span>: <span class="math display">\[\Sigma_{i,j} = \text{cov} (X_i,X_j)\]</span></p></li>
<li>Si <span class="math inline">\(A\)</span> est une matrice de rang <span class="math inline">\(m \leq n\)</span>, alors <span class="math inline">\(XA\)</span> suit la loi <span class="math inline">\(\mathcal{N}(\mu A,A&#39; \Sigma A)\)</span>
</div>
</li>
</ul>
</div>
<div id="lois-issues-de-la-loi-normale" class="section level2">
<h2><span class="header-section-number">4.7</span> Lois issues de la loi normale</h2>
<p>On dispose de variables aléatoires correspondants aux résultats d’un même expérience aléatoire <span class="math inline">\(X_1,\ldots,X_n\)</span> dont on suppose qu’elle sont de loi normale <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> pour des quantités <span class="math inline">\(\mu,\sigma\)</span> non observée. On cherche à estimer ces quantités. Pour celà, on va considérer la moyenne empirique <span class="math display">\[\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i\]</span> comme estimateur de <span class="math inline">\(\mu\)</span> et la variance empirique <span class="math display">\[S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2\]</span> comme estimateur de <span class="math inline">\(\sigma^2\)</span>.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-69" class="theorem"><strong>Théorème 4.12  </strong></span>Soit <span class="math inline">\(X_1,\ldots,X_n\)</span> des variables aléatoires indépendantes, de même loi <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span>.</p>
<ul>
<li><p><span class="math inline">\(\overline{X}\)</span> et <span class="math inline">\(S^2\)</span> sont indépendants;</p></li>
<li><p><span class="math inline">\(\overline{X} \sim \mathcal{N}(\mu,\sigma^2 / n)\)</span></p></li>
<li><span class="math inline">\((n-1)S^2/\sigma^2 \sim \Gamma(\frac12, \frac{n-1}{2})\)</span>. Cette dernière loi s’appelle la <strong>loi du <span class="math inline">\(\chi^2\)</span> à <span class="math inline">\(n-1\)</span> degrés de liberté</strong>, notée <span class="math inline">\(\chi^2(n-1)\)</span> ; c’est la loi de la somme des carrés de <span class="math inline">\(n-1\)</span> lois normales centrées réduites indépendantes.</li>
<li><p>Les variables aléatoires <span class="math display">\[ U = \frac{n-1}{\sigma^2}S^2 \sim \chi^2(n-1)\]</span> et <span class="math display">\[V = \frac{\sqrt{n}}{\sigma}(\overline{X}-\mu) \sim \mathcal{N}(0,1).\]</span> Elles ne dépendent pas de <span class="math inline">\(\sigma\)</span>. Le ratio <span class="math display">\[T = \frac{V}{\sqrt{U/(n-1)}}\]</span> dont le numérateur suit <span class="math inline">\(\mathcal{N}(0,1)\)</span> et le dénominateur est la racine d’un <span class="math inline">\(\chi^2(n-1)\)</span>, divisé par <span class="math inline">\(n-1\)</span> suit une <strong>loi de Student</strong>, de paramètre <span class="math inline">\(n-1\)</span>, notée <span class="math inline">\(t(n-1)\)</span>.</p></li>
<li>Soient <span class="math inline">\(U,V\)</span> deux variables aléatoires qui suivent respectivement les lois <span class="math inline">\(\chi^2(r)\)</span> et <span class="math inline">\(\chi^2(s)\)</span>, alors <span class="math display">\[F = \frac{U/r}{V/s}\]</span> suit une <strong>loi de Fisher</strong> de paramètres <span class="math inline">\((r,s)\)</span>, notée <span class="math inline">\(F(r,s)\)</span>. Dans ce cas, <span class="math inline">\(1/F\)</span> suit la loi <span class="math inline">\(F(s,r)\)</span> et si <span class="math inline">\(T \sim t(r)\)</span>, <span class="math inline">\(T^2 \sim F(1,r)\)</span>
</div>
</li>
</ul>

</div>
</div>



<!-- On peut ajouter des blocs (cf https://github.com/rstudio/bookdown/blob/master/inst/examples/css/style.css +  https://github.com/rstudio/bookdown/blob/master/inst/examples/02-components.Rmd) -->
<!-- il faut penser à modifier le css -->
<!-- # Références -->

</div>



</div>
            </section>

          </div>
        </div>
      </div>
<a href="variables-aleatoires-discretes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistique-descriptive.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["coursProbaStats.pdf", "coursProbaStats.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
